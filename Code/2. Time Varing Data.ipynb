{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.ticker as mtick\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('SBA_Loan_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state(state1,state2,state3):\n",
    "    state_list = [state1,state2,state3]\n",
    "    for state in state_list:\n",
    "        if state in ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']:\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subprogram(subprogram):\n",
    "    if subprogram == 'Sec. 504 - Loan Guarantees - Private Sector Financed':\n",
    "        return 'Private Sector Financed'\n",
    "    elif subprogram == 'Sec. 504 - Delta loans, funded 9/26/95':\n",
    "        return 'Delta loans'\n",
    "    elif subprogram == 'Sec. 504 - Premier Certified Lender Program':\n",
    "        return 'Premier Certified Lender Program'\n",
    "    else:\n",
    "        return 'Refinance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_NaicsCode_indicator(NaicsCode):\n",
    "    if not math.isnan(NaicsCode):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_NaicsCode(NaicsCode):\n",
    "    if not math.isnan(NaicsCode):\n",
    "        return str(NaicsCode)[:2]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_zipcode(state):\n",
    "    if not math.isnan(state):\n",
    "        return str(state)[:3]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_enddate(ChargeOffDate,LoanStatus,TermInMonths,ApprovalDate):\n",
    "    if LoanStatus == 'CHGOFF':\n",
    "        return ChargeOffDate\n",
    "    elif LoanStatus == 'PIF':\n",
    "        date_1 = pd.to_datetime(ApprovalDate) + np.timedelta64(int(TermInMonths), 'M')\n",
    "        date_2 = pd.to_datetime('2014-01-31')\n",
    "        return min(date_1,date_2)\n",
    "    else:\n",
    "        return '2014-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_status(status):\n",
    "    if status == 'PIF':\n",
    "        return 1\n",
    "    elif status == 'CHGOFF':\n",
    "        return 2\n",
    "    elif status == 'EXEMPT':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_index(date):\n",
    "    date = str(date)\n",
    "    return (int(date[:4])-1990)*4 + int((int(date[5:7])-1)//3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df[df['LoanStatus']!='CANCLD']\n",
    "    df = df[df['TermInMonths']!=0]\n",
    "    df = df[df['LoanStatus'].isna()==False]\n",
    "    df['sub_zipcode'] = df.apply(lambda row : format_zipcode(row['BorrZip']), axis = 1)\n",
    "    df['check_state'] = df.apply(lambda row : check_state(row['BorrState'],row['CDC_State'],row['ProjectState']), axis = 1)\n",
    "    df = df[df['check_state']==True]\n",
    "    df['is_Same_Borr_CDC'] = df['BorrState'] == df['CDC_State']\n",
    "    df['is_Same_Borr_Project'] = df['BorrState'] == df['ProjectState']\n",
    "    df['log_amount'] = np.log(df['GrossApproval'])\n",
    "    df['loan_purpose'] = df.apply(lambda row : format_subprogram(row['subpgmdesc']), axis = 1)\n",
    "    df['indicator_NaicsCode'] = df.apply(lambda row : format_NaicsCode_indicator(row['NaicsCode']), axis = 1)\n",
    "    df['sub_NaicsCode'] = df.apply(lambda row : format_NaicsCode(row['NaicsCode']), axis = 1)\n",
    "    df['end_date'] = df.apply(lambda row:format_enddate(row['ChargeOffDate'],row['LoanStatus'],row['TermInMonths'],row['ApprovalDate']),axis=1)\n",
    "    df = df.drop(columns=['Program', 'BorrName','BorrStreet','BorrCity','CDC_Name','CDC_Street','CDC_City',\n",
    "                          'ThirdPartyLender_Name','ThirdPartyLender_City','ThirdPartyLender_State','ThirdPartyDollars',\n",
    "                          'ApprovalFiscalYear','DeliveryMethod','InitialInterestRate','NaicsDescription','ProjectCounty',\n",
    "                          'subpgmdesc','NaicsCode','CDC_State','CDC_Zip','check_state','BorrZip'])\n",
    "    df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'])\n",
    "    df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "    df['ApprovalYear'] = df['ApprovalDate'].dt.year\n",
    "    df['EndYear'] = df['end_date'].dt.year\n",
    "    begin = pd.to_datetime('1990-01-01')\n",
    "    df['start_index'] = df.apply(lambda row:get_quarter_index(row['ApprovalDate']),axis=1)\n",
    "    df['end_index'] = df.apply(lambda row:get_quarter_index(row['end_date']),axis=1)\n",
    "    df['start_day'] = round((df['ApprovalDate'] - begin)/np.timedelta64(1, 'D')).astype('int')\n",
    "    df['end_day'] = round((df['end_date'] - begin)/np.timedelta64(1, 'D')).astype('int')\n",
    "    df['time'] = df['end_day'] - df['start_day']\n",
    "    df['status'] = df.apply(lambda row:format_status(row['LoanStatus']),axis=1)\n",
    "    df = df.reset_index()\n",
    "    df['id'] = df.index\n",
    "    df = df.drop(columns=['index'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_death(status,index,end):\n",
    "    if index == end and status == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_quarter_day(index,quarter_list):\n",
    "    return quarter_list[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_start_list():\n",
    "    quarter_list = []\n",
    "    start = pd.to_datetime('1990-01-01')\n",
    "    current = pd.to_datetime('1990-01-01')\n",
    "    while current<=pd.to_datetime('2014-10-01'):\n",
    "        days = round((current - start)/np.timedelta64(1, 'D'))\n",
    "        quarter_list.append(days)\n",
    "        current = str(current)\n",
    "        if current[5:7] == '01':\n",
    "            current = current[:5] + '04' + '-01'\n",
    "        elif current[5:7] == '04':\n",
    "            current = current[:5] + '07' + '-01'\n",
    "        elif current[5:7] == '07':\n",
    "            current = current[:5] + '10' + '-01'\n",
    "        else:\n",
    "            current = str(int(current[:4])+1) + '-01' + '-01'\n",
    "        current = pd.to_datetime(current)\n",
    "        \n",
    "    return quarter_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_end_list():\n",
    "    quarter_list = []\n",
    "    start = pd.to_datetime('1990-01-01')\n",
    "    current = pd.to_datetime('1990-03-31')\n",
    "    while current<=pd.to_datetime('2014-12-31'):\n",
    "        days = round((current - start)/np.timedelta64(1, 'D'))\n",
    "        quarter_list.append(days)\n",
    "        current = str(current)\n",
    "        if current[5:7] == '03':\n",
    "            current = current[:5] + '06' + '-30'\n",
    "        elif current[5:7] == '06':\n",
    "            current = current[:5] + '09' + '-30'\n",
    "        elif current[5:7] == '09':\n",
    "            current = current[:5] + '12' + '-31'\n",
    "        else:\n",
    "            current = str(int(current[:4])+1) + '-03' + '-31'\n",
    "        current = pd.to_datetime(current)\n",
    "        \n",
    "    return quarter_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_window(df):\n",
    "    df_1 = df.copy()\n",
    "    df_1['index_gap'] = df['end_index'] - df['start_index'] + 1\n",
    "    df_1['cum_index'] = df_1['index_gap'].cumsum()\n",
    "    df_1['cum_index'] = df_1['cum_index'] - df_1['index_gap']\n",
    "    df_1 = df_1.loc[df_1.index.repeat(df_1['index_gap'])]\n",
    "    df_1['loan_index'] = df_1.index\n",
    "    df_1 = df_1.reset_index()\n",
    "    df_1['row_index'] = df_1.index\n",
    "    df_1['quarter_index'] = df_1['start_index'] + df_1['row_index'] - df_1['cum_index']\n",
    "    df_1 = df_1.drop(columns=['loan_index','row_index','cum_index','index_gap','index'])\n",
    "    df_1['death'] = df_1.apply(lambda row:format_death(row['status'],row['quarter_index'],row['end_index']),axis=1)\n",
    "    quarter_start_list = get_quarter_start_list()\n",
    "    quarter_end_list = get_quarter_end_list()\n",
    "    df_1['quarter_start_day'] = df_1.apply(lambda row:format_quarter_day(row['quarter_index'],quarter_start_list),axis=1)\n",
    "    df_1['quarter_end_day'] = df_1.apply(lambda row:format_quarter_day(row['quarter_index'],quarter_end_list),axis=1)\n",
    "    df_1['time_start'] = df_1.apply(lambda row:max(row['quarter_start_day'],row['start_day']),axis=1)\n",
    "    df_1['time_end'] = df_1.apply(lambda row:min(row['quarter_end_day']+1,row['end_day']),axis=1)\n",
    "    \n",
    "    return df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = split_window(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixed = pd.read_csv('data/FixedVariables.csv')\n",
    "df_gsp = pd.read_csv('data/GSP_StateLevel.csv')\n",
    "df_PI = pd.read_csv('data/PersonalIncome_StateLevel.csv')\n",
    "df_unemploy = pd.read_csv('data/UnemploymentRate_StateLevel.csv')\n",
    "df_industry = pd.read_csv('data/IndustryGDP_97-14.csv')\n",
    "df_hpi = pd.read_csv('data/HPI.csv')\n",
    "df_leverage = pd.read_csv('data/Leverage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_csv(df):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df.set_index('index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_column(df,name):\n",
    "    df.columns.name = name\n",
    "    df = df.stack()\n",
    "    df.name = 'value'\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"index\": \"quarter_index\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fixed(df1,df2,left_index):\n",
    "    df2 = format_csv(df2)\n",
    "    df2[left_index] = df2.index\n",
    "    df = df1.merge(df2,left_on = left_index,right_on=left_index,how='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_level(df1,df2,level_name,left_feature,feature_name):\n",
    "    df2 = format_csv(df2)\n",
    "    df2 = stack_column(df2,level_name)\n",
    "    df = df1.merge(df2,left_on = ['quarter_index',left_feature],right_on =['quarter_index',level_name],how='left')\n",
    "    df = df.drop(columns=[level_name]) \n",
    "    df = df.rename(columns={\"value\": feature_name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = combine_fixed(df,df_fixed[['Unnamed: 0','date','index','S&P500','VIX']],'end_index')\n",
    "df_combined = combine_fixed(df_combined,df_fixed[['Unnamed: 0','date','index','TED','PRIME']],'start_index')\n",
    "df_combined = combine_fixed(df_combined,df_leverage,'end_index')\n",
    "df_combined = combine_level(df_combined,df_gsp,'state','ProjectState','GSP')\n",
    "df_combined = combine_level(df_combined,df_PI,'state','ProjectState','PersonalIncome')\n",
    "df_combined = combine_level(df_combined,df_unemploy,'state','ProjectState','UnemploymentRate')\n",
    "df_combined = combine_level(df_combined,df_industry,'industry','sub_NaicsCode','IndustryGDP')\n",
    "df_combined = combine_level(df_combined,df_hpi,'zipcode','sub_zipcode','HPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_impute(df,name):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df[~df[name].isna()]\n",
    "    df = df.set_index('index')\n",
    "    return df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_impute(df):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df.set_index('index')\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index'])\n",
    "    sub = dict(df.iloc[0])\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_impute = get_fixed_impute(df_leverage,'Leverage')\n",
    "hpi_impute = get_level_impute(df_hpi)\n",
    "industry_impute = get_level_impute(df_industry)\n",
    "unemploy_impute = get_level_impute(df_unemploy)\n",
    "PI_impute = get_level_impute(df_PI)\n",
    "gsp_impute = get_level_impute(df_gsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_missing_indicator(feature):\n",
    "    if not math.isnan(feature):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_impute(feature,level,impute):\n",
    "    if not math.isnan(feature):\n",
    "        return feature\n",
    "    else:\n",
    "        if level == None:\n",
    "            return impute\n",
    "        else:\n",
    "            try:\n",
    "                return impute[str(level)]\n",
    "            except:\n",
    "                return min(impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['indicator_Leverage'] = df_combined.apply(lambda row : format_missing_indicator(row['Leverage']), axis = 1)\n",
    "df_combined['Leverage'] = df_combined.apply(lambda row : format_impute(row['Leverage'],None,leverage_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_HPI'] = df_combined.apply(lambda row : format_missing_indicator(row['HPI']), axis = 1)\n",
    "df_combined['HPI'] = df_combined.apply(lambda row : format_impute(row['HPI'],row['sub_zipcode'],hpi_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_IndustryGDP'] = df_combined.apply(lambda row : format_missing_indicator(row['IndustryGDP']), axis = 1)\n",
    "df_combined['IndustryGDP'] = df_combined.apply(lambda row : format_impute(row['IndustryGDP'],row['sub_NaicsCode'],industry_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_UnemploymentRate'] = df_combined.apply(lambda row : format_missing_indicator(row['UnemploymentRate']), axis = 1)\n",
    "df_combined['UnemploymentRate'] = df_combined.apply(lambda row : format_impute(row['UnemploymentRate'],row['ProjectState'],unemploy_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_PersonalIncome'] = df_combined.apply(lambda row : format_missing_indicator(row['PersonalIncome']), axis = 1)\n",
    "df_combined['PersonalIncome'] = df_combined.apply(lambda row : format_impute(row['PersonalIncome'],row['ProjectState'],PI_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_GSP'] = df_combined.apply(lambda row : format_missing_indicator(row['GSP']), axis = 1)\n",
    "df_combined['GSP'] = df_combined.apply(lambda row : format_impute(row['GSP'],row['ProjectState'],gsp_impute), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv('time_independent_portfolio_500_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios_list = list(id_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sample(loan_id,portfolios_list):\n",
    "    if loan_id in portfolios_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_1 = df_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_1['sample'] = df_combined.apply(lambda row:format_sample(row['id'],portfolios_list),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios = df_combined_1[df_combined_1['sample']==1]\n",
    "df_train = df_combined_1[df_combined_1['sample']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios = df_portfolios.drop(columns=['sample'])\n",
    "df_train = df_train.drop(columns=['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('time_varing_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios.to_csv('time_varing_portfolio_500_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('time_varing_combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhaoyiting/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_loss = pd.read_csv('combined_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_df = pd.read_csv('time_independent_portfolio_500_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios_list = list(id_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sample(loan_id,portfolios_list):\n",
    "    if loan_id in portfolios_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss['sample'] = df_loss.apply(lambda row:format_sample(row['id'],portfolios_list),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = df_loss[df_loss['sample']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = df_loss.drop(columns=['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss = df_loss[df_loss['death']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loss.to_csv('loss_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
