{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loss_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ChargeOffDate'] = pd.to_datetime(df['ChargeOffDate'])\n",
    "df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'])\n",
    "df['loan_age'] = (df['ChargeOffDate'] - df['ApprovalDate'])/np.timedelta64(1, 'M')\n",
    "df['loss_pcrt'] = df['GrossChargeOffAmount'] / df['GrossApproval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0','LoanStatus','log_amount','end_date','quarter_index','ApprovalDate','ChargeOffDate',\n",
    "                      'ChargeOffDate','time','status','id','death','time_start','time_end','ApprovalYear','EndYear',\n",
    "                     'BorrState','indicator_Leverage','indicator_HPI','indicator_IndustryGDP',\n",
    "                     'indicator_UnemploymentRate', 'indicator_PersonalIncome',\n",
    "                     'indicator_GSP','indicator_NaicsCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rocovery(amount):\n",
    "    if amount==0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fully_Recovery'] = df.apply(lambda row:format_rocovery(row['GrossChargeOffAmount']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:-1000,:]\n",
    "df_test = df.iloc[-1000:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['Fully_Recovery','GrossChargeOffAmount','loss_pcrt','GrossApproval'])\n",
    "Y_train = df_train['loss_pcrt']\n",
    "X_test = df_test.drop(columns=['Fully_Recovery','GrossChargeOffAmount','loss_pcrt','GrossApproval'])\n",
    "Y_test = df_test['loss_pcrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'max_depth' : [7,8,10],\n",
    "    'min_samples_leaf': [6,10]\n",
    "}\n",
    "\n",
    "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), \n",
    "                      param_grid=grid, \n",
    "                      cv= 5)\n",
    "CV_rfr = CV_rfr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = CV_rfr.best_estimator_\n",
    "regr = regr.fit(X_train, Y_train)\n",
    "\n",
    "prediction = regr.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, prediction)\n",
    "mse**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recovery Probability Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Fully_Recovery','GrossChargeOffAmount','loss_pcrt','GrossApproval'])\n",
    "Y = df_train['Fully_Recovery']\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.5)\n",
    "under = RandomUnderSampler(sampling_strategy=0.9)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X_train, Y_train = pipeline.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'max_depth' : [7,8,10],\n",
    "    'min_samples_leaf': [6,10]\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=RandomForestClassifier(), \n",
    "                      param_grid=grid, \n",
    "                      cv= 5,\n",
    "                      scoring = 'roc_auc')\n",
    "CV_clf = CV_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CV_clf.best_estimator_\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_recall(y_true, y_pred):   \n",
    "    y_pred = pd.Series(y_pred, index=y_true.index)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for i in y_true.index: \n",
    "        if y_true[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    try:\n",
    "        precision = TP / (TP + FP)\n",
    "    except:\n",
    "        precision = 1    \n",
    "    try:\n",
    "        recall = TP / (TP + FN)\n",
    "    except:\n",
    "        recall = 1\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = clf.predict_proba(X_valid)[:, 1]\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "probability_thresholds = np.linspace(0, 1, num=100)\n",
    "for p in probability_thresholds:\n",
    "    y_test_preds = []\n",
    "    for prob in y_test_probs:\n",
    "        if prob > p:\n",
    "            y_test_preds.append(1)\n",
    "        else:\n",
    "            y_test_preds.append(0)            \n",
    "    precision, recall = calc_precision_recall(Y_valid, y_test_preds)        \n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(recall_scores, precision_scores, label='Random Forest Classfier')\n",
    "baseline = len(Y_valid[Y_valid==1]) / len(Y_valid)\n",
    "ax.plot([0, 1], [baseline, baseline], linestyle='--', label='Baseline')\n",
    "ax.set_xlabel('Recall',fontsize = 14)\n",
    "ax.set_ylabel('Precision',fontsize=14)\n",
    "ax.legend(loc='center left')\n",
    "plt.title('Precision-recall Curve',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(auc(recall_scores, precision_scores),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict_proba(X_valid)[:,1]\n",
    "y_pred = [0 if x < 0.9 else 1 for x in prediction]\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Fully_Recovery','GrossChargeOffAmount','loss_pcrt','GrossApproval'])\n",
    "Y = df_train['loss_pcrt']\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['sqrt','log2'],\n",
    "    'max_depth' : [7,8,10],\n",
    "    'min_samples_leaf': [6,10]\n",
    "}\n",
    "\n",
    "CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), \n",
    "                      param_grid=grid, \n",
    "                      cv= 5)\n",
    "CV_rfr = CV_rfr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = CV_rfr.best_estimator_\n",
    "regr = regr.fit(X_train, Y_train)\n",
    "\n",
    "prediction = regr.predict(X_valid)\n",
    "mse = mean_squared_error(Y_valid, prediction)\n",
    "mse**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = regr.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop(columns=['Fully_Recovery','GrossChargeOffAmount','loss_pcrt','GrossApproval'])\n",
    "Y_test = df_test['loss_pcrt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_squared_error(Y_loss_test, prediction_recovery,prediction_loss,threshold):\n",
    "    y_pred_recovery = [1 if x <threshold else 0 for x in prediction_recovery]\n",
    "    y_pred_loss = np.array(y_pred_recovery) * np.array(prediction_loss)\n",
    "    mse = mean_squared_error(Y_loss_test,y_pred_loss)\n",
    "    return mse**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_recovery = clf.predict_proba(X_test)[:,1]\n",
    "prediction_loss = regr.predict(X_test)\n",
    "get_mean_squared_error(Y_test, prediction_recovery,prediction_loss,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_recovery = clf.predict_proba(X_test)[:,1]\n",
    "prediction_loss = regr.predict(X_test)\n",
    "rmse_scores = []\n",
    "mini = 1000000000\n",
    "best_p = 1\n",
    "probability_thresholds = np.linspace(0, 1, num=100)\n",
    "for p in probability_thresholds:\n",
    "    y_pred_recovery = [1 if x <p else 0 for x in prediction_recovery]\n",
    "    y_pred_loss = np.array(y_pred_recovery) * np.array(prediction_loss)\n",
    "    mse = mean_squared_error(Y_test,y_pred_loss)\n",
    "    rmse_scores.append(mse**.5)\n",
    "    if mse**.5<mini:\n",
    "        mini = mse**.5\n",
    "        best_p = p\n",
    "mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ax.plot(probability_thresholds,rmse_scores)\n",
    "ax.set_xlabel('thresholds',fontsize = 14)\n",
    "ax.set_ylabel('rmse',fontsize = 14)\n",
    "plt.title('RMSE Score by Threshold', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'classifier_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'regressor_model.sav'\n",
    "pickle.dump(regr, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
