{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib.ticker as mtick\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current Dataset Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('SBA_Loan_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(string):\n",
    "    return string != string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state(state1,state2,state3):\n",
    "    state_list = [state1,state2,state3]\n",
    "    for state in state_list:\n",
    "        if state in ['AK', 'AL', 'AR', 'AZ', 'CA', 'CO', 'CT', 'DC', 'DE', 'FL', 'GA',\n",
    "           'HI', 'IA', 'ID', 'IL', 'IN', 'KS', 'KY', 'LA', 'MA', 'MD', 'ME',\n",
    "           'MI', 'MN', 'MO', 'MS', 'MT', 'NC', 'ND', 'NE', 'NH', 'NJ', 'NM',\n",
    "           'NV', 'NY', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX',\n",
    "           'UT', 'VA', 'VT', 'WA', 'WI', 'WV', 'WY']:\n",
    "            continue\n",
    "        else:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subprogram(subprogram):\n",
    "    if subprogram == 'Sec. 504 - Loan Guarantees - Private Sector Financed':\n",
    "        return 'Private Sector Financed'\n",
    "    elif subprogram == 'Sec. 504 - Delta loans, funded 9/26/95':\n",
    "        return 'Delta loans'\n",
    "    elif subprogram == 'Sec. 504 - Premier Certified Lender Program':\n",
    "        return 'Premier Certified Lender Program'\n",
    "    else:\n",
    "        return 'Refinance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_NaicsCode_indicator(NaicsCode):\n",
    "    if not math.isnan(NaicsCode):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_NaicsCode(NaicsCode):\n",
    "    if not math.isnan(NaicsCode):\n",
    "        return str(NaicsCode)[:2]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_zipcode(state):\n",
    "    if not math.isnan(state):\n",
    "        return str(state)[:3]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_enddate(ChargeOffDate,LoanStatus,TermInMonths,ApprovalDate):\n",
    "    if LoanStatus == 'CHGOFF':\n",
    "        return ChargeOffDate\n",
    "    elif LoanStatus == 'PIF':\n",
    "        date_1 = pd.to_datetime(ApprovalDate) + np.timedelta64(int(TermInMonths), 'M')\n",
    "        date_2 = pd.to_datetime('2014-01-31')\n",
    "        return min(date_1,date_2)\n",
    "    else:\n",
    "        return '2014-01-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_status(status):\n",
    "    if status == 'PIF':\n",
    "        return 1\n",
    "    elif status == 'CHGOFF':\n",
    "        return 2\n",
    "    elif status == 'EXEMPT':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarter_index(date):\n",
    "    date = str(date)\n",
    "    return (int(date[:4])-1990)*4 + int((int(date[5:7])-1)//3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df[df['LoanStatus']!='CANCLD']\n",
    "    df = df[df['TermInMonths']!=0]\n",
    "    df = df[df['LoanStatus'].isna()==False]\n",
    "    df['sub_zipcode'] = df.apply(lambda row : format_zipcode(row['BorrZip']), axis = 1)\n",
    "    df['check_state'] = df.apply(lambda row : check_state(row['BorrState'],row['CDC_State'],row['ProjectState']), axis = 1)\n",
    "    df = df[df['check_state']==True]\n",
    "    df['is_Same_Borr_CDC'] = df['BorrState'] == df['CDC_State']\n",
    "    df['is_Same_Borr_Project'] = df['BorrState'] == df['ProjectState']\n",
    "    df['log_amount'] = np.log(df['GrossApproval'])\n",
    "    df['loan_purpose'] = df.apply(lambda row : format_subprogram(row['subpgmdesc']), axis = 1)\n",
    "    df['indicator_NaicsCode'] = df.apply(lambda row : format_NaicsCode_indicator(row['NaicsCode']), axis = 1)\n",
    "    df['sub_NaicsCode'] = df.apply(lambda row : format_NaicsCode(row['NaicsCode']), axis = 1)\n",
    "    df['end_date'] = df.apply(lambda row:format_enddate(row['ChargeOffDate'],row['LoanStatus'],row['TermInMonths'],row['ApprovalDate']),axis=1)\n",
    "    df = df.drop(columns=['Program', 'BorrName','BorrStreet','BorrCity','CDC_Name','CDC_Street','CDC_City',\n",
    "                          'ThirdPartyLender_Name','ThirdPartyLender_City','ThirdPartyLender_State','ThirdPartyDollars',\n",
    "                          'ApprovalFiscalYear','DeliveryMethod','InitialInterestRate','NaicsDescription','ProjectCounty',\n",
    "                          'subpgmdesc','NaicsCode','CDC_State','CDC_Zip','check_state','BorrZip'])\n",
    "    df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'])\n",
    "    df['end_date'] = pd.to_datetime(df['end_date'])\n",
    "    df['ApprovalYear'] = df['ApprovalDate'].dt.year\n",
    "    df['EndYear'] = df['end_date'].dt.year\n",
    "    begin = pd.to_datetime('1990-01-01')\n",
    "    df['start_index'] = df.apply(lambda row:get_quarter_index(row['ApprovalDate']),axis=1)\n",
    "    df['end_index'] = df.apply(lambda row:get_quarter_index(row['end_date']),axis=1)\n",
    "    df['start_day'] = round((df['ApprovalDate'] - begin)/np.timedelta64(1, 'D')).astype('int')\n",
    "    df['end_day'] = round((df['end_date'] - begin)/np.timedelta64(1, 'D')).astype('int')\n",
    "    df['time'] = df['end_day'] - df['start_day']\n",
    "    df['status'] = df.apply(lambda row:format_status(row['LoanStatus']),axis=1)\n",
    "    df = df.reset_index()\n",
    "    df['id'] = df.index\n",
    "    df = df.drop(columns=['index'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge with Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fixed = pd.read_csv('data/FixedVariables.csv')\n",
    "df_gsp = pd.read_csv('data/GSP_StateLevel.csv')\n",
    "df_PI = pd.read_csv('data/PersonalIncome_StateLevel.csv')\n",
    "df_unemploy = pd.read_csv('data/UnemploymentRate_StateLevel.csv')\n",
    "df_industry = pd.read_csv('data/IndustryGDP_97-14.csv')\n",
    "df_hpi = pd.read_csv('data/HPI.csv')\n",
    "df_leverage = pd.read_csv('data/Leverage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_csv(df):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df.set_index('index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_column(df,name):\n",
    "    df.columns.name = name\n",
    "    df = df.stack()\n",
    "    df.name = 'value'\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns={\"index\": \"quarter_index\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fixed(df1,df2,left_index):\n",
    "    df2 = format_csv(df2)\n",
    "    df2['quarter_index'] = df2.index\n",
    "    df = df1.merge(df2,left_on = left_index,right_on='quarter_index',how='left')\n",
    "    df = df.drop(columns=['quarter_index']) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_level(df1,df2,level_name,left_feature,feature_name):\n",
    "    df2 = format_csv(df2)\n",
    "    df2 = stack_column(df2,level_name)\n",
    "    df = df1.merge(df2,left_on = ['start_index',left_feature],right_on =['quarter_index',level_name],how='left')\n",
    "    df = df.drop(columns=[level_name]) \n",
    "    df = df.drop(columns=['quarter_index']) \n",
    "    df = df.rename(columns={\"value\": feature_name})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = combine_fixed(df,df_fixed[['Unnamed: 0','date','index','S&P500','VIX']],'end_index')\n",
    "df_combined = combine_fixed(df_combined,df_fixed[['Unnamed: 0','date','index','TED','PRIME']],'start_index')\n",
    "df_combined = combine_fixed(df_combined,df_leverage,'end_index')\n",
    "df_combined = combine_level(df_combined,df_gsp,'state','ProjectState','GSP')\n",
    "df_combined = combine_level(df_combined,df_PI,'state','ProjectState','PersonalIncome')\n",
    "df_combined = combine_level(df_combined,df_unemploy,'state','ProjectState','UnemploymentRate')\n",
    "df_combined = combine_level(df_combined,df_industry,'industry','sub_NaicsCode','IndustryGDP')\n",
    "df_combined = combine_level(df_combined,df_hpi,'zipcode','sub_zipcode','HPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_impute(df,name):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df[~df[name].isna()]\n",
    "    df = df.set_index('index')\n",
    "    return df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level_impute(df):\n",
    "    df = df.drop(columns=['Unnamed: 0','date'])  \n",
    "    df = df.set_index('index')\n",
    "    df = df.dropna()\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index'])\n",
    "    sub = dict(df.iloc[0])\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "leverage_impute = get_fixed_impute(df_leverage,'Leverage')\n",
    "hpi_impute = get_level_impute(df_hpi)\n",
    "industry_impute = get_level_impute(df_industry)\n",
    "unemploy_impute = get_level_impute(df_unemploy)\n",
    "PI_impute = get_level_impute(df_PI)\n",
    "gsp_impute = get_level_impute(df_gsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_missing_indicator(feature):\n",
    "    if not math.isnan(feature):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_impute(feature,level,impute):\n",
    "    if not math.isnan(feature):\n",
    "        return feature\n",
    "    else:\n",
    "        if level == None:\n",
    "            return impute\n",
    "        else:\n",
    "            try:\n",
    "                return impute[str(level)]\n",
    "            except:\n",
    "                return min(impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['indicator_Leverage'] = df_combined.apply(lambda row : format_missing_indicator(row['Leverage']), axis = 1)\n",
    "df_combined['Leverage'] = df_combined.apply(lambda row : format_impute(row['Leverage'],None,leverage_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_HPI'] = df_combined.apply(lambda row : format_missing_indicator(row['HPI']), axis = 1)\n",
    "df_combined['HPI'] = df_combined.apply(lambda row : format_impute(row['HPI'],row['sub_zipcode'],hpi_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_IndustryGDP'] = df_combined.apply(lambda row : format_missing_indicator(row['IndustryGDP']), axis = 1)\n",
    "df_combined['IndustryGDP'] = df_combined.apply(lambda row : format_impute(row['IndustryGDP'],row['sub_NaicsCode'],industry_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_UnemploymentRate'] = df_combined.apply(lambda row : format_missing_indicator(row['UnemploymentRate']), axis = 1)\n",
    "df_combined['UnemploymentRate'] = df_combined.apply(lambda row : format_impute(row['UnemploymentRate'],row['ProjectState'],unemploy_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_PersonalIncome'] = df_combined.apply(lambda row : format_missing_indicator(row['PersonalIncome']), axis = 1)\n",
    "df_combined['PersonalIncome'] = df_combined.apply(lambda row : format_impute(row['PersonalIncome'],row['ProjectState'],PI_impute), axis = 1)\n",
    "\n",
    "df_combined['indicator_GSP'] = df_combined.apply(lambda row : format_missing_indicator(row['GSP']), axis = 1)\n",
    "df_combined['GSP'] = df_combined.apply(lambda row : format_impute(row['GSP'],row['ProjectState'],gsp_impute), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(df_combined['id'][df_combined['ApprovalYear']>=2010].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolios_list = sample(id_list,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sample(loan_id,portfolios_list):\n",
    "    if loan_id in portfolios_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_1 = df_combined.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_1['sample'] = df_combined.apply(lambda row:format_sample(row['id'],portfolios_list),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios = df_combined_1[df_combined_1['sample']==1]\n",
    "df_train = df_combined_1[df_combined_1['sample']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios = df_portfolios.drop(columns=['sample'])\n",
    "df_train = df_train.drop(columns=['sample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('time_independent_training_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_portfolios.to_csv('time_independent_portfolio_500_loans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.to_csv('time_independent_combined_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
